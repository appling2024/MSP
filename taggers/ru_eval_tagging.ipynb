{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем текст из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rueval_2010_goldstandard_text.txt', encoding='windows-1251') as f:\n",
    "    brusov_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rueval_2010_goldstandard_tagged.txt', encoding='windows-1251') as f:\n",
    "    f.readline()\n",
    "    goldstandard = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = []\n",
    "for line in goldstandard.split('\\n'):\n",
    "    DATA.append(line.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(DATA, columns=['Wordform_GS2', 'Lemma_GS2', 'POS_GS2', 'Gram_GS2', 'Status', 'NB'])\n",
    "df = df[['Wordform_GS2', 'Lemma_GS2', 'POS_GS2', 'Gram_GS2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wordform_GS2</th>\n",
       "      <th>Lemma_GS2</th>\n",
       "      <th>POS_GS2</th>\n",
       "      <th>Gram_GS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Цветки</td>\n",
       "      <td>цветок</td>\n",
       "      <td>S</td>\n",
       "      <td>m,nom,pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>дикорастущих</td>\n",
       "      <td>дикорастущий</td>\n",
       "      <td>A</td>\n",
       "      <td>gen,pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>форм</td>\n",
       "      <td>форма</td>\n",
       "      <td>S</td>\n",
       "      <td>f,gen,pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>обыкновенной</td>\n",
       "      <td>обыкновенный</td>\n",
       "      <td>A</td>\n",
       "      <td>f,gen,sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сирени</td>\n",
       "      <td>сирень</td>\n",
       "      <td>S</td>\n",
       "      <td>f,gen,sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>ведется</td>\n",
       "      <td>вестись</td>\n",
       "      <td>V</td>\n",
       "      <td>3p,pres,sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>по</td>\n",
       "      <td>по</td>\n",
       "      <td>PR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>плану</td>\n",
       "      <td>план</td>\n",
       "      <td>S</td>\n",
       "      <td>dat,m,sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2908 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wordform_GS2     Lemma_GS2 POS_GS2    Gram_GS2\n",
       "0           Цветки        цветок       S    m,nom,pl\n",
       "1     дикорастущих  дикорастущий       A      gen,pl\n",
       "2             форм         форма       S    f,gen,pl\n",
       "3     обыкновенной  обыкновенный       A    f,gen,sg\n",
       "4           сирени        сирень       S    f,gen,sg\n",
       "...            ...           ...     ...         ...\n",
       "2903       ведется       вестись       V  3p,pres,sg\n",
       "2904            по            по      PR            \n",
       "2905         плану          план       S    dat,m,sg\n",
       "2906             .                                  \n",
       "2907                        None    None        None\n",
       "\n",
       "[2908 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "from pymorphy3.tokenizers import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brusov_tokenized_pymorphy = simple_word_tokenize(brusov_text)\n",
    "# for token in brusov_tokenized_pymorphy:\n",
    "#     parsed_token = morph.parse(token)\n",
    "#     print('{:3}\\t{:10}\\t{:50}'.format(len(parsed_token), parsed_token[0].word, parsed_token[0].tag._str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brusov_tokenized_pymorphy = simple_word_tokenize(brusov_text)\n",
    "# brusov_pymorphy = []\n",
    "# for token in brusov_tokenized_pymorphy:\n",
    "#     parsed_token = morph.parse(token)\n",
    "#     brusov_pymorphy.append((parsed_token[0].word, parsed_token[0].tag._str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(brusov_pymorphy, columns=['token', 'tag'])\n",
    "df.to_excel('brusov_pymorphy.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачиваем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размечаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(brusov_text)\n",
    "brusov_spacy = []\n",
    "for token in doc:\n",
    "    brusov_spacy.append((token.text, token.pos_, token.morph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(brusov_spacy, columns=['token', 'pos',  'tag'])\n",
    "df.to_excel('brusov_spacy.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pymystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "analyzer_no_disamb = Mystem()\n",
    "analyzer_with_disamb = Mystem(disambiguation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brusov_mystem = []\n",
    "doc_no_disamb = analyzer_no_disamb.analyze(brusov_text)\n",
    "doc_with_disamb = analyzer_with_disamb.analyze(brusov_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brusov_pymystem = []\n",
    "for i in range(len(doc_no_disamb)):\n",
    "    has_ana = doc_no_disamb[i].get('analysis')\n",
    "    if has_ana:\n",
    "        text = doc_no_disamb[i].get('text')\n",
    "        ana_no_disamb = doc_no_disamb[i].get('analysis')[0]\n",
    "        gr_no_disamb = ana_no_disamb.get('gr')\n",
    "        \n",
    "        ana_with_disamb = doc_with_disamb[i].get('analysis')[0]\n",
    "        gr_with_disamb = ana_with_disamb.get('gr')\n",
    "        brusov_pymystem.append((text, gr_no_disamb, gr_with_disamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(brusov_pymystem, columns=['token', 'gr_no_disamb', 'gr_with_disamb'])\n",
    "df.to_excel('brusov_pymystem.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='ru', processors='tokenize,pos', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "brusov_stanza = []\n",
    "doc = nlp(brusov_text)\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        brusov_stanza.append((word.text, word.upos, word.feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(brusov_stanza, columns=['text', 'upos', 'feats'])\n",
    "df.to_excel('brusov_stanza.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufal.udpipe import Model, Pipeline\n",
    "model = Model.load('russian-ud-2.0-170801.udpipe')\n",
    "pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed = pipeline.process(brusov_text)\n",
    "brusov_ud = []\n",
    "for i, sent in enumerate(analyzed.split('\\n\\n')):\n",
    "    for j, token in enumerate(sent.split('\\n')):\n",
    "        if (not token.startswith('#')) and token:\n",
    "            brusov_ud.append(token.split('\\t')[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brusov_ud[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(brusov_ud, columns=['text', 'lemma', 'pos1', 'pos2', 'morph'])\n",
    "df.to_excel('brusov_ud.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
